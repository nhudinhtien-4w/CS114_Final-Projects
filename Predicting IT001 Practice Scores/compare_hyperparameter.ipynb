{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12246854,"sourceType":"datasetVersion","datasetId":7716610}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import r2_score\n\n# === Đọc dữ liệu ===\ndf = pd.read_csv('/kaggle/input/data-diem/annonimized.csv')\ndf_score = pd.read_csv('/kaggle/input/data-diem/th-public.csv')\n\ndf_score[\"TH\"] = df_score[\"TH\"].astype(str).str.replace('\\xa0', '').str.strip()\ndf_score[\"TH\"] = pd.to_numeric(df_score[\"TH\"], errors='coerce')\n\ndf.columns = [\n    'assignment_id',\n    'problem_id',\n    'username',\n    'is_final',\n    'status',\n    'pre_score',\n    'coefficient',\n    'language_id',\n    'created_at',\n    'updated_at',\n    'judgement'\n]\n\ndef extract_judgement_features(judgement_str):\n    try:\n        j = json.loads(judgement_str)\n        times = j.get(\"times\", [])\n        mems = j.get(\"mems\", [])\n        verdicts = j.get(\"verdicts\", {})\n        total = len(times)\n        wrong = verdicts.get(\"WRONG\", 0)\n        correct = total - wrong\n        return pd.Series({\n            \"total_tests\": total,\n            \"correct_tests\": correct,\n            \"correct_rate\": correct / total if total > 0 else 0,\n            \"avg_time\": np.mean(times) if times else 0,\n            \"avg_mem\": np.mean(mems) if mems else 0,\n            \"wrong_tests\": wrong\n        })\n    except:\n        return pd.Series({\n            \"total_tests\": 0,\n            \"correct_tests\": 0,\n            \"correct_rate\": 0,\n            \"avg_time\": 0,\n            \"avg_mem\": 0,\n            \"wrong_tests\": 0\n        })\n\njudgement_features = df[\"judgement\"].apply(extract_judgement_features)\ndf = pd.concat([df, judgement_features], axis=1)\n\ndf[\"created_at\"] = pd.to_datetime(\"2025-\" + df[\"created_at\"], format=\"%Y-%m-%d %H:%M:%S\", errors='coerce')\ndf[\"is_correct\"] = (df[\"pre_score\"] == 10000).astype(int)\ndf[\"is_late\"] = (df[\"coefficient\"] < 100).astype(int)\ndf[\"is_scored\"] = (df[\"status\"] == \"SCORE\").astype(int)\ndf[\"day\"] = df[\"created_at\"].dt.date\n\nfeature_df = df.groupby(\"username\").agg({\n    \"assignment_id\": \"nunique\",\n    \"problem_id\": \"nunique\",\n    \"pre_score\": [\"count\", \"mean\", \"max\"],\n    \"coefficient\": \"mean\",\n    \"wrong_tests\": \"mean\",\n    \"is_correct\": \"sum\",\n    \"is_late\": \"sum\",\n    \"is_scored\": \"sum\",\n    \"day\": \"nunique\",\n    \"correct_rate\": \"mean\",\n    \"avg_time\": \"mean\",\n    \"avg_mem\": \"mean\"\n})\n\nfeature_df.columns = [\n    \"num_assignments\", \"num_problems\", \"num_submissions\",\n    \"avg_score\", \"max_score\", \"avg_penalty\", \"avg_wrong_tests\",\n    \"num_correct\", \"num_late\", \"num_score_status\", \"active_days\",\n    \"mean_correct_rate\", \"mean_time_per_test\", \"mean_mem_per_test\"\n]\n\nfeature_df[\"score_ratio\"] = feature_df[\"num_score_status\"] / feature_df[\"num_submissions\"]\nfeature_df[\"correct_ratio\"] = feature_df[\"num_correct\"] / feature_df[\"num_submissions\"]\nfeature_df[\"late_ratio\"] = feature_df[\"num_late\"] / feature_df[\"num_submissions\"]\n\nfeature_df.reset_index(inplace=True)\n\ndf_score = df_score.rename(columns={\"hash\": \"username\"})\nmerged = feature_df.merge(df_score, on=\"username\", how=\"left\")\n\ntrain_data = merged[~merged[\"TH\"].isna()].copy()\ntest_data = merged[merged[\"TH\"].isna()].copy()\ntrain_data[\"TH\"] = train_data[\"TH\"].astype(float)\n\nX_cols = [\n    \"num_assignments\", \"num_problems\", \"num_submissions\",\n    \"avg_score\", \"max_score\", \"avg_penalty\", \"avg_wrong_tests\",\n    \"num_correct\", \"num_late\", \"num_score_status\", \"active_days\",\n    \"score_ratio\", \"correct_ratio\", \"late_ratio\",\n    \"mean_correct_rate\", \"mean_time_per_test\", \"mean_mem_per_test\"\n]\n\nX_train = train_data[X_cols]\ny_train = train_data[\"TH\"]\n\n# === Random Forest với GridSearchCV ===\nparam_grid_rf = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [8, 10, 12],\n    'min_samples_split': [2, 5, 10]\n}\ngrid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=3, scoring='r2', n_jobs=-1)\ngrid_search_rf.fit(X_train, y_train)\n\n# === Linear Regression ===\nlr = LinearRegression()\nlr_score = np.mean(cross_val_score(lr, X_train, y_train, cv=3, scoring='r2'))\n\n# === GridSearchCV cho SVR ===\nparam_grid_svr = {\n    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n    'C': [0.1, 1.0, 10],\n    'epsilon': [0.1, 0.2, 0.5]\n}\ngrid_search_svr = GridSearchCV(SVR(), param_grid_svr, cv=3, scoring='r2', n_jobs=-1)\ngrid_search_svr.fit(X_train, y_train)\n\n# === In kết quả ===\nprint(\"=== So sánh các mô hình (R^2 CV score) ===\")\nprint(f\"Random Forest (best): {grid_search_rf.best_score_:.4f} với params {grid_search_rf.best_params_}\")\nprint(f\"Linear Regression: {lr_score:.4f}\")\nprint(f\"SVR (best): {grid_search_svr.best_score_:.4f} với params {grid_search_svr.best_params_}\")\n\n# Lấy best_model từ Random Forest\nbest_model = grid_search_rf.best_estimator_\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T05:20:04.450188Z","iopub.execute_input":"2025-07-01T05:20:04.450492Z","iopub.status.idle":"2025-07-01T05:21:18.092114Z","shell.execute_reply.started":"2025-07-01T05:20:04.450471Z","shell.execute_reply":"2025-07-01T05:21:18.091354Z"}},"outputs":[{"name":"stdout","text":"=== So sánh các mô hình (R^2 CV score) ===\nRandom Forest (best): 0.3543 với params {'max_depth': 12, 'min_samples_split': 10, 'n_estimators': 200}\nLinear Regression: 0.2677\nSVR (best): 0.1926 với params {'C': 10, 'epsilon': 0.5, 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":3}]}